{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2debd60-88fb-4d6c-bc62-9804e51c8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9df7e43-c5dd-46bf-9778-741d2a87864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "sea_level = pd.read_csv(\"inputs/sealevel.csv\")\n",
    "data = pd.read_csv(\"inputs/Zip_homes.csv\")\n",
    "\n",
    "#Housing price data\n",
    "transposed_data = data.T\n",
    "\n",
    "transposed_data.reset_index(inplace=True)\n",
    "new_header = transposed_data.iloc[0]\n",
    "transposed_data = transposed_data[1:]\n",
    "transposed_data.columns = new_header\n",
    "\n",
    "transposed_data.rename(columns={'RegionName': 'Year'}, inplace=True)\n",
    "transposed_data.set_index('Year', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a87eed-7380-444c-8ef7-0244681adddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewbosland/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:1189: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Sea Level Data\n",
    "filtered_data = sea_level[::3]\n",
    "\n",
    "years = filtered_data['Year'].unique()\n",
    "limited_rows = []\n",
    "\n",
    "for year in years:\n",
    "    year_data = filtered_data[filtered_data['Year'] == year]\n",
    "    limited_rows.append(year_data.iloc[:12])\n",
    "\n",
    "filtered_data = pd.concat(limited_rows)\n",
    "\n",
    "filtered_data['Year'] = pd.to_datetime(filtered_data['Year'], format='%Y') + filtered_data.groupby('Year').cumcount().apply(lambda x: DateOffset(months=x))\n",
    "filtered_data['Year'] = filtered_data['Year'].dt.to_period('M').astype(str)\n",
    "\n",
    "filtered_data = filtered_data[~filtered_data.index.duplicated(keep='first')]\n",
    "\n",
    "filtered_data.set_index('Year', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91107d72-0cc5-4b38-a31d-9ce187c90003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two data sets\n",
    "merged_data = pd.merge(transposed_data, filtered_data, how='outer', left_index=True, right_index=True)\n",
    "merged_data.rename(columns={'Year': 'Date'}, inplace=True)\n",
    "merged_data.index = merged_data.index.rename('Date')\n",
    "\n",
    "merged_data.to_csv('inputs/merged_data.csv')\n",
    "\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5262a2-f237-47ab-971b-65f121b19e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_merged_data = merged_data.loc['2010-01':'2021-06']\n",
    "\n",
    "print(filtered_merged_data.head())\n",
    "\n",
    "filtered_merged_data.to_csv('inputs/filtered_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50781f-6238-455d-a7ac-3ba83b5a7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Coastal = [36532.0, 36605.0, 99501.0, 94015.0, 93950.0, 93109.0, 77505.0, 19968.0, 19963.0, 19901.0, 19720.0, 33137.0, 33129.0, 33131.0, 33308.0, 33062.0, 32226.0, 96778.0, 70124.0, 70122.0, 70126.0, 39501.0, 29412.0, 29577.0, 29582.0, 77058.0, 77015.0, 21403.0, 21122.0, 21220.0, 10305.0, 10314.0, 11214.0, 10069.0, 10010.0, 28468.0, 23518.0, 23661.0]\n",
    "Inland = [36576.0, 36606.0, 99508.0, 94014.0, 93940.0, 93108.0, 77504.0, 19947.0, 19960.0, 19904.0, 19702.0, 33127.0, 33145.0, 33130.0, 33309.0, 33060.0, 32218.0, 96771.0, 70118.0, 70119.0, 70116.0, 39503.0, 29407.0, 29579.0, 29566.0, 77062.0, 77020.0, 21401.0, 21060.0, 21237.0, 10304.0, 10306.0, 11204.0, 10023.0, 10003.0, 28467.0, 23502.0, 23666.0]\n",
    "Combined = [36532.0, 36576.0, 36605.0, 36606.0, 99501.0, 99508.0, 94015.0, 94014.0, 93950.0, 93940.0, 93109.0, 93108.0, 77505.0, 77504.0, 19968.0, 19947.0, 19963.0, 19960.0, 19901.0, 19904.0, 19720.0, 19702.0, 33137.0, 33127.0, 33129.0, 33145.0, 33131.0, 33130.0, 33308.0, 33309.0, 33062.0, 33060.0, 32226.0, 32218.0, 96778.0, 96771.0, 70124.0, 70118.0, 70122.0, 70119.0, 70126.0, 70116.0, 39501.0, 39503.0, 29412.0, 29407.0, 29577.0, 29579.0, 29582.0, 29566.0, 77058.0, 77062.0, 77015.0, 77020.0, 21403.0, 21401.0, 21122.0, 21060.0, 21220.0, 21237.0, 10305.0, 10304.0, 10314.0, 10306.0, 11214.0, 11204.0, 10069.0, 10023.0, 10010.0, 10003.0, 28468.0, 28467.0, 23518.0, 23502.0, 23661.0, 23666.0]\n",
    "\n",
    "additional_columns = [\n",
    "    \"TotalWeightedObservations\",\n",
    "    \"GMSL_noGIA\",\n",
    "    \"StdDevGMSL_noGIA\",\n",
    "    \"SmoothedGSML_noGIA\",\n",
    "    \"GMSL_GIA\",\n",
    "    \"StdDevGMSL_GIA\",\n",
    "    \"SmoothedGSML_GIA\",\n",
    "    \"SmoothedGSML_GIA_sigremoved\",\n",
    "]\n",
    "\n",
    "selected_columns = Coastal + Inland + additional_columns\n",
    "\n",
    "filtered_zip = filtered_merged_data.loc[:, selected_columns]\n",
    "filtered_zip = filtered_zip.reset_index()\n",
    "\n",
    "# Transpose the DataFrame\n",
    "transposed_filtered_zip = filtered_zip.transpose()\n",
    "\n",
    "# Reset the index to create a new column with the index values\n",
    "transposed_filtered_zip = transposed_filtered_zip.reset_index()\n",
    "\n",
    "# Rename the first column to \"Zip\" instead of \"Date\"\n",
    "transposed_filtered_zip = transposed_filtered_zip.rename(columns={'index': 'Zip'})\n",
    "\n",
    "# Set the dates as column names\n",
    "transposed_filtered_zip.columns = transposed_filtered_zip.iloc[0]\n",
    "transposed_filtered_zip = transposed_filtered_zip.drop(transposed_filtered_zip.index[0])\n",
    "\n",
    "transposed_filtered_zip = transposed_filtered_zip.rename(columns={'Date': 'Zip'})\n",
    "\n",
    "# Add the \"Coastal/Inland\" and \"Pair\" columns\n",
    "transposed_filtered_zip['Inland/Coastal'] = transposed_filtered_zip['Zip'].apply(lambda x: 1 if x in Coastal else 0)\n",
    "transposed_filtered_zip['Pair'] = 0\n",
    "pair_index = 1\n",
    "\n",
    "for i in range(0, len(Combined), 2):\n",
    "    inland_zip = Combined[i]\n",
    "    coastal_zip = Combined[i+1]\n",
    "    transposed_filtered_zip.loc[transposed_filtered_zip['Zip'] == inland_zip, 'Pair'] = pair_index\n",
    "    transposed_filtered_zip.loc[transposed_filtered_zip['Zip'] == coastal_zip, 'Pair'] = pair_index\n",
    "    pair_index += 1\n",
    "\n",
    "# Sort the DataFrame by the \"Pair\" column\n",
    "transposed_filtered_zip = transposed_filtered_zip.sort_values(by='Pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b6825-c63d-49dd-ade3-942b7610f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transposed DataFrame to a new CSV file\n",
    "transposed_filtered_zip.to_csv('inputs/transposed_filtered_zip.csv', index=False)\n",
    "print(transposed_filtered_zip.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e349869-1c6a-4568-954c-1c01ee35df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt dataset - Rearrange data\n",
    "transposed_filtered_zip = transposed_filtered_zip.iloc[8:]\n",
    "melted_df = transposed_filtered_zip.melt(id_vars=['Zip', 'Inland/Coastal', 'Pair'],\n",
    "                    var_name='Date',\n",
    "                    value_name='Price')\n",
    "print(melted_df)\n",
    "# Filter melted_df based on the first date range (2010-01 to 2017-09)\n",
    "melted_df_1 = melted_df.loc[melted_df['Date'] <= '2017-09']\n",
    "\n",
    "# Prep sea level data for merge and filter for the first date range (2010-01 to 2017-09)\n",
    "filtered_data_1 = filtered_data.loc['2010-01':'2017-09'].reset_index()\n",
    "# Merge:\n",
    "zip_sea = pd.merge(melted_df_1, filtered_data_1.rename(columns={'Year': 'Date'}),\n",
    "         on='Date', how='outer', validate='many_to_one')\n",
    "\n",
    "zip_sea.to_csv('inputs/zip_sea.csv', index=False)\n",
    "\n",
    "# Filter melted_df based on the second date range (2017-10 to 2021-06)\n",
    "melted_df_2 = melted_df.loc[(melted_df['Date'] >= '2017-10') & (melted_df['Date'] <= '2021-06')]\n",
    "\n",
    "# Prep sea level data for merge and filter for the second date range (2017-10 to 2021-06)\n",
    "filtered_data_2 = filtered_data.loc['2017-10':'2021-06'].reset_index()\n",
    "# Merge:\n",
    "zip_sea_new = pd.merge(melted_df_2, filtered_data_2.rename(columns={'Year': 'Date'}),\n",
    "         on='Date', how='outer', validate='many_to_one')\n",
    "\n",
    "zip_sea_new.to_csv('inputs/zip_sea_new.csv', index=False)\n",
    "(zip_sea, zip_sea_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8aacc0-7411-48ec-bab4-762a1c6a079b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
