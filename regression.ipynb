{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa491d4-8e42-4376-b0d7-26ed96509b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coastal Model: MSE = 102638953429.67212 R2 Score = 0.055241377493726596\n",
      "Inland Model: MSE = 391926714673.39233 R2 Score = 0.01867078612204509\n",
      "Coastal Model Coefficient: 5548.0718445512775\n",
      "Inland Model Coefficient: 8015.089114738455\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset using the given file path\n",
    "zip_sea = pd.read_csv('inputs/zip_sea.csv')\n",
    "\n",
    "# Remove rows with missing values in 'Price' column\n",
    "zip_sea = zip_sea.dropna(subset=['Price'])\n",
    "\n",
    "# Split the dataset into coastal and inland subsets\n",
    "coastal_data = zip_sea[zip_sea['Inland/Coastal'] == 1]\n",
    "inland_data = zip_sea[zip_sea['Inland/Coastal'] == 0]\n",
    "\n",
    "# Get the X and y values for both coastal and inland data\n",
    "X_coastal = coastal_data[['GMSL_noGIA']]\n",
    "y_coastal = coastal_data['Price']\n",
    "X_inland = inland_data[['GMSL_noGIA']]\n",
    "y_inland = inland_data['Price']\n",
    "\n",
    "# Split the coastal and inland datasets into training and testing sets\n",
    "X_coastal_train, X_coastal_test, y_coastal_train, y_coastal_test = train_test_split(X_coastal, y_coastal, test_size=0.2, random_state=42)\n",
    "X_inland_train, X_inland_test, y_inland_train, y_inland_test = train_test_split(X_inland, y_inland, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression models for both coastal and inland data\n",
    "coastal_model = LinearRegression()\n",
    "inland_model = LinearRegression()\n",
    "\n",
    "coastal_model.fit(X_coastal_train, y_coastal_train)\n",
    "inland_model.fit(X_inland_train, y_inland_train)\n",
    "\n",
    "# Evaluate the models using the testing sets and calculate the mean squared error and R-squared score\n",
    "y_coastal_pred = coastal_model.predict(X_coastal_test)\n",
    "y_inland_pred = inland_model.predict(X_inland_test)\n",
    "\n",
    "mse_coastal = mean_squared_error(y_coastal_test, y_coastal_pred)\n",
    "mse_inland = mean_squared_error(y_inland_test, y_inland_pred)\n",
    "\n",
    "r2_coastal = r2_score(y_coastal_test, y_coastal_pred)\n",
    "r2_inland = r2_score(y_inland_test, y_inland_pred)\n",
    "\n",
    "print(\"Coastal Model: MSE =\", mse_coastal, \"R2 Score =\", r2_coastal)\n",
    "print(\"Inland Model: MSE =\", mse_inland, \"R2 Score =\", r2_inland)\n",
    "\n",
    "# Print the coefficients of the models\n",
    "print(\"Coastal Model Coefficient:\", coastal_model.coef_[0])\n",
    "print(\"Inland Model Coefficient:\", inland_model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f84846-18c0-4b1c-bc1a-57010ae359da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coastal Model: MSE = 102638953429.67212 R2 Score = 0.055241377493726596\n",
      "Inland Model: MSE = 391926714673.39233 R2 Score = 0.01867078612204509\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.037\n",
      "Model:                            OLS   Adj. R-squared:                  0.037\n",
      "Method:                 Least Squares   F-statistic:                     79.39\n",
      "Date:                Tue, 02 May 2023   Prob (F-statistic):           1.10e-18\n",
      "Time:                        16:31:37   Log-Likelihood:                -28994.\n",
      "No. Observations:                2056   AIC:                         5.799e+04\n",
      "Df Residuals:                    2054   BIC:                         5.800e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.913e+05    1.8e+04     10.628      0.000    1.56e+05    2.27e+05\n",
      "GMSL_noGIA  5548.0718    622.653      8.910      0.000    4326.974    6769.169\n",
      "==============================================================================\n",
      "Omnibus:                     1835.365   Durbin-Watson:                   1.920\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            53463.656\n",
      "Skew:                           4.264   Prob(JB):                         0.00\n",
      "Kurtosis:                      26.481   Cond. No.                         73.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.019\n",
      "Model:                            OLS   Adj. R-squared:                  0.019\n",
      "Method:                 Least Squares   F-statistic:                     34.28\n",
      "Date:                Tue, 02 May 2023   Prob (F-statistic):           5.69e-09\n",
      "Time:                        16:31:37   Log-Likelihood:                -25640.\n",
      "No. Observations:                1735   AIC:                         5.128e+04\n",
      "Df Residuals:                    1733   BIC:                         5.130e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.723e+05   4.11e+04      4.193      0.000    9.17e+04    2.53e+05\n",
      "GMSL_noGIA  8015.0891   1368.872      5.855      0.000    5330.274    1.07e+04\n",
      "==============================================================================\n",
      "Omnibus:                     1589.190   Durbin-Watson:                   2.038\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            37691.936\n",
      "Skew:                           4.527   Prob(JB):                         0.00\n",
      "Kurtosis:                      23.963   Cond. No.                         81.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset using the given file path\n",
    "zip_sea = pd.read_csv('inputs/zip_sea.csv')\n",
    "\n",
    "# Remove rows with missing values in 'Price' column\n",
    "zip_sea = zip_sea.dropna(subset=['Price'])\n",
    "\n",
    "# Split the dataset into coastal and inland subsets\n",
    "coastal_data = zip_sea[zip_sea['Inland/Coastal'] == 1]\n",
    "inland_data = zip_sea[zip_sea['Inland/Coastal'] == 0]\n",
    "\n",
    "# Get the X and y values for both coastal and inland data\n",
    "X_coastal = coastal_data[['GMSL_noGIA']]\n",
    "y_coastal = coastal_data['Price']\n",
    "X_inland = inland_data[['GMSL_noGIA']]\n",
    "y_inland = inland_data['Price']\n",
    "\n",
    "# Split the coastal and inland datasets into training and testing sets\n",
    "X_coastal_train, X_coastal_test, y_coastal_train, y_coastal_test = train_test_split(X_coastal, y_coastal, test_size=0.2, random_state=42)\n",
    "X_inland_train, X_inland_test, y_inland_train, y_inland_test = train_test_split(X_inland, y_inland, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression models for both coastal and inland data\n",
    "coastal_model = LinearRegression()\n",
    "inland_model = LinearRegression()\n",
    "\n",
    "coastal_model.fit(X_coastal_train, y_coastal_train)\n",
    "inland_model.fit(X_inland_train, y_inland_train)\n",
    "\n",
    "# Evaluate the models using the testing sets and calculate the mean squared error and R-squared score\n",
    "y_coastal_pred = coastal_model.predict(X_coastal_test)\n",
    "y_inland_pred = inland_model.predict(X_inland_test)\n",
    "\n",
    "mse_coastal = mean_squared_error(y_coastal_test, y_coastal_pred)\n",
    "mse_inland = mean_squared_error(y_inland_test, y_inland_pred)\n",
    "\n",
    "r2_coastal = r2_score(y_coastal_test, y_coastal_pred)\n",
    "r2_inland = r2_score(y_inland_test, y_inland_pred)\n",
    "\n",
    "print(\"Coastal Model: MSE =\", mse_coastal, \"R2 Score =\", r2_coastal)\n",
    "print(\"Inland Model: MSE =\", mse_inland, \"R2 Score =\", r2_inland)\n",
    "\n",
    "# Output model summaries using statsmodels\n",
    "coastal_model_sm = sm.OLS(y_coastal_train, sm.add_constant(X_coastal_train)).fit()\n",
    "inland_model_sm = sm.OLS(y_inland_train, sm.add_constant(X_inland_train)).fit()\n",
    "\n",
    "print(coastal_model_sm.summary())\n",
    "print(inland_model_sm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce46ba09-cffb-4f4f-9b9e-aab8db5c1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MSE = 43955404998.66471 R2 Score = 0.8209418082930526\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.887\n",
      "Model:                            OLS   Adj. R-squared:                  0.886\n",
      "Method:                 Least Squares   F-statistic:                     756.3\n",
      "Date:                Tue, 02 May 2023   Prob (F-statistic):               0.00\n",
      "Time:                        16:34:07   Log-Likelihood:                -50960.\n",
      "No. Observations:                3791   AIC:                         1.020e+05\n",
      "Df Residuals:                    3751   BIC:                         1.022e+05\n",
      "Df Model:                          39                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const           2.465e+05   1.79e+04     13.794      0.000    2.11e+05    2.82e+05\n",
      "Inland/Coastal -3.176e+04   5746.615     -5.526      0.000    -4.3e+04   -2.05e+04\n",
      "GMSL_noGIA      1148.2825    255.016      4.503      0.000     648.299    1648.266\n",
      "Pair_2         -1.856e+05   2.46e+04     -7.550      0.000   -2.34e+05   -1.37e+05\n",
      "Pair_3          6467.6975   2.32e+04      0.279      0.780   -3.89e+04    5.19e+04\n",
      "Pair_4          4.167e+05    2.5e+04     16.636      0.000    3.68e+05    4.66e+05\n",
      "Pair_5          5.062e+05   2.25e+04     22.466      0.000    4.62e+05     5.5e+05\n",
      "Pair_6          2.772e+06   2.63e+04    105.294      0.000    2.72e+06    2.82e+06\n",
      "Pair_7         -5.861e+04   2.38e+04     -2.460      0.014   -1.05e+05   -1.19e+04\n",
      "Pair_8         -7405.0650   2.11e+04     -0.351      0.726   -4.88e+04    3.39e+04\n",
      "Pair_9         -4.319e+04   2.16e+04     -2.002      0.045   -8.55e+04    -903.697\n",
      "Pair_10        -6.839e+04   2.11e+04     -3.237      0.001    -1.1e+05    -2.7e+04\n",
      "Pair_11        -7.528e+04   2.19e+04     -3.440      0.001   -1.18e+05   -3.24e+04\n",
      "Pair_12         1.475e+05   3.42e+04      4.318      0.000    8.06e+04    2.15e+05\n",
      "Pair_13         1.719e+05   2.45e+04      7.020      0.000    1.24e+05     2.2e+05\n",
      "Pair_14         1.657e+05   2.25e+04      7.355      0.000    1.22e+05     2.1e+05\n",
      "Pair_15         3.185e+04   2.29e+04      1.394      0.163   -1.29e+04    7.67e+04\n",
      "Pair_16         7.228e+04   2.33e+04      3.105      0.002    2.66e+04    1.18e+05\n",
      "Pair_17        -6.102e+04   2.54e+04     -2.407      0.016   -1.11e+05   -1.13e+04\n",
      "Pair_18        -7.189e+04   2.23e+04     -3.218      0.001   -1.16e+05   -2.81e+04\n",
      "Pair_19         1.286e+05    2.4e+04      5.361      0.000    8.16e+04    1.76e+05\n",
      "Pair_20        -1.764e+04    3.1e+04     -0.568      0.570   -7.85e+04    4.32e+04\n",
      "Pair_21        -5.213e+04   2.74e+04     -1.902      0.057   -1.06e+05    1600.554\n",
      "Pair_22        -1.453e+05   2.09e+04     -6.943      0.000   -1.86e+05   -1.04e+05\n",
      "Pair_23         3.035e+04   2.57e+04      1.182      0.237      -2e+04    8.07e+04\n",
      "Pair_24        -9.557e+04   2.29e+04     -4.176      0.000    -1.4e+05   -5.07e+04\n",
      "Pair_25        -6.994e+04   2.25e+04     -3.108      0.002   -1.14e+05   -2.58e+04\n",
      "Pair_26        -8.411e+04   2.43e+04     -3.459      0.001   -1.32e+05   -3.64e+04\n",
      "Pair_27        -1.394e+05   2.43e+04     -5.743      0.000   -1.87e+05   -9.18e+04\n",
      "Pair_28         1.927e+05   2.11e+04      9.121      0.000    1.51e+05    2.34e+05\n",
      "Pair_29         2.205e+04   2.12e+04      1.038      0.299   -1.96e+04    6.37e+04\n",
      "Pair_30        -6.804e+04    2.2e+04     -3.087      0.002   -1.11e+05   -2.48e+04\n",
      "Pair_31         1.698e+05   2.15e+04      7.892      0.000    1.28e+05    2.12e+05\n",
      "Pair_32         1.605e+05   2.18e+04      7.348      0.000    1.18e+05    2.03e+05\n",
      "Pair_33         3.879e+05   2.58e+04     15.042      0.000    3.37e+05    4.38e+05\n",
      "Pair_34         2.142e+06   3.61e+04     59.362      0.000    2.07e+06    2.21e+06\n",
      "Pair_35         2.147e+06   3.38e+04     63.604      0.000    2.08e+06    2.21e+06\n",
      "Pair_36        -6.946e+04   2.43e+04     -2.862      0.004   -1.17e+05   -2.19e+04\n",
      "Pair_37        -5.616e+04   2.09e+04     -2.688      0.007   -9.71e+04   -1.52e+04\n",
      "Pair_38         -1.04e+05   2.14e+04     -4.868      0.000   -1.46e+05   -6.21e+04\n",
      "==============================================================================\n",
      "Omnibus:                     3654.370   Durbin-Watson:                   2.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           710780.919\n",
      "Skew:                          -4.104   Prob(JB):                         0.00\n",
      "Kurtosis:                      69.576   Cond. No.                     1.08e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.08e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset using the given file path\n",
    "zip_sea = pd.read_csv('inputs/zip_sea.csv')\n",
    "\n",
    "# Remove rows with missing values in 'Price' column\n",
    "zip_sea = zip_sea.dropna(subset=['Price'])\n",
    "\n",
    "# Create dummy variables for the 'Pair' column\n",
    "pair_dummies = pd.get_dummies(zip_sea['Pair'], prefix='Pair', drop_first=True)\n",
    "zip_sea = pd.concat([zip_sea, pair_dummies], axis=1)\n",
    "\n",
    "# Get the X and y values\n",
    "X = zip_sea[['Inland/Coastal', 'GMSL_noGIA'] + list(pair_dummies.columns)]\n",
    "y = zip_sea['Price']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using the testing set and calculate the mean squared error and R-squared score\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model: MSE =\", mse, \"R2 Score =\", r2)\n",
    "\n",
    "# Output model summary using statsmodels\n",
    "model_sm = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "print(model_sm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2afb651d-8c71-472c-9423-e197733415e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.tools.eval_measures' has no attribute 'r_squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate the model using the testing set and calculate the R-squared score\u001b[39;00m\n\u001b[1;32m     23\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredPrice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test)\n\u001b[0;32m---> 24\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_measures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_squared\u001b[49m(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m], test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredPrice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: R2 Score =\u001b[39m\u001b[38;5;124m\"\u001b[39m, r2)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Output the model summary\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels.tools.eval_measures' has no attribute 'r_squared'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset using the given file path\n",
    "zip_sea = pd.read_csv('inputs/zip_sea.csv')\n",
    "\n",
    "# Remove rows with missing values in 'Price' column\n",
    "zip_sea = zip_sea.dropna(subset=['Price'])\n",
    "\n",
    "# Create the model formula\n",
    "formula = 'Price ~ Date * Q(\"Inland/Coastal\") + C(Pair)'\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train, test = train_test_split(zip_sea, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the model using the training set\n",
    "model = smf.ols(formula, data=train).fit()\n",
    "\n",
    "# Evaluate the model using the testing set and calculate the R-squared score\n",
    "test['PredPrice'] = model.predict(test)\n",
    "r2 = sm.tools.eval_measures.r_squared(test['Price'], test['PredPrice'])\n",
    "\n",
    "print(\"Model: R2 Score =\", r2)\n",
    "\n",
    "# Output the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78959635-2ef3-4025-9047-00f9c178485d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
